{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23587fa",
   "metadata": {},
   "source": [
    "# BELIEFS IN FREE-FORM TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3c5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from math import exp\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from typing import Any, Literal\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from anthropic import Anthropic\n",
    "from openai import OpenAI\n",
    "\n",
    "from datasets import load_dataset_builder\n",
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_split_names\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "import anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004649dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.getenv('OPENAI_API_KEY') is not None, \"You must set your OpenAI API key\"\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1237967",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    # api_key=\"my_api_key\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178aa5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = \"gpt-4-1106-preview\"\n",
    "gpt35 = \"gpt-3.5-turbo-1106\"\n",
    "MODELS = [gpt35, gpt4 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1fce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = \"claude-opus-4-20250514\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db6af9",
   "metadata": {},
   "source": [
    "## Testing Agreement of T with P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80cd46",
   "metadata": {},
   "source": [
    "Design & implement a simple pipeline for measuring beliefs in free-form text, and sense-check this pipeline with diverse hand-crafted test cases. \n",
    "The pipeline would, for example, take as input proposition P and free-form text T (e.g. a short essay), and outputs a real in [0,1] indicating to what extent T agrees/disagrees with P. \n",
    "The pipeline can be prompting-based, logprob-based, embedding-based, or anything else you think makes sense - whatever does the job well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b643a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_json(file_name) -> dict:\n",
    "    with open(file_name, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def extract_belief_regex(text):\n",
    "    pattern = r'{\"belief\":\\s*([0-9]*\\.?[0-9]+)'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b138ca",
   "metadata": {},
   "source": [
    "- The data is all long text esssays over a wide range of topics, although there are only 7 in total.\n",
    "- It would make more sense to scrape data or pick up a debate datset\n",
    "    - 1) (The GRE issues essays - the text itself is something I wrote and is therefore something atleast a little ambiguous- . The score seems to faithfully represent that)(it also has mistakes owing to the time constraint - so seemed like a realistic test).\n",
    "    - 2) The opinions json has 5 articles, ranging from greek gods and feminism to relegion and well, pride and perjudice :')\n",
    "- These might not be the typical beliefs or propositions that need testing, but I thought the ambiguity, and binary stances make it a sensible choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e666e",
   "metadata": {},
   "source": [
    "Prompting with logprobs and checking for confidence would give better insights, but skipping that, cos - time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5d3f4e",
   "metadata": {},
   "source": [
    "## Simple Prompting - Binary Stances/Beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "468c35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "\n",
    "You are a discerning and sensible debate expert. I need your help scoring a text's agreement to a given belief. Answer with a float in the range [0,1], with 0 being strong disagreement with the proposition/belief and 1 being strong agreement.\n",
    "\n",
    "\n",
    "I have a text, and would like to know to what extent it agrees with my proposition: \"{prop}as opposed to \"{neg_prop}.\n",
    "Represent this agreement score by a floating-point probability in [0,1]. \n",
    "Respond in this format, with nothing else: {{\"belief\": float}}\n",
    "\n",
    "The text that you need to check for belief: {text}\n",
    "\n",
    "Remember that you are estimating the probability of \"{prop}\" being the correct answer, not \"{neg_prop}\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# \n",
    "# Do not return an explanation.\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a discerning and sensible debate expert. I need your help scoring a text's agreement to a given belief. Answer with a float in the range [0,1], with 0 being strong disagreement with the proposition/belief and 1 being strong agreement.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6a229b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A basic prompting based pipeline\"\"\"\n",
    "\n",
    "def get_belief(text, proposition, neg_prop, model) -> str:\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": USER_PROMPT.format(prop=proposition, neg_prop=neg_prop, text=text),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=history,\n",
    "        max_tokens=100,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fe12e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_belief_claude(text, proposition, neg_prop, model) -> str:\n",
    "    history = [\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": USER_PROMPT.format(prop=proposition, neg_prop=neg_prop, text=text),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        messages=history\n",
    "    )\n",
    "    return (message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5fd44153",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = load_from_json(\"my_gre.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c427164",
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[]\n",
    "for rec in essays:\n",
    "    proposition = rec['proposition']\n",
    "    neg_prop = rec['neg_prop']\n",
    "    text = rec['text']\n",
    "\n",
    "    presp = get_belief_claude(text, proposition, neg_prop, claude)\n",
    "    \n",
    "    #switch P\n",
    "    temp = neg_prop\n",
    "    neg_prop = proposition\n",
    "    proposition = temp\n",
    "    negp_resp = get_belief_claude(text, proposition, neg_prop, claude)\n",
    "    l.append((proposition, neg_prop, extract_belief_regex(presp[0].text), extract_belief_regex(negp_resp[0].text)))\n",
    "ess_df = pd.DataFrame(l, columns=['P', 'NotP', 'Pscore', 'NPscore'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31d62bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>NotP</th>\n",
       "      <th>Pscore</th>\n",
       "      <th>NPscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People's behaviour is seldom ever determined b...</td>\n",
       "      <td>People's behaviour is largely determined by fo...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A nation should not require all of its student...</td>\n",
       "      <td>A nation should require all of its students to...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   P  \\\n",
       "0  People's behaviour is seldom ever determined b...   \n",
       "1  A nation should not require all of its student...   \n",
       "\n",
       "                                                NotP  Pscore  NPscore  \n",
       "0  People's behaviour is largely determined by fo...    0.75     0.15  \n",
       "1  A nation should require all of its students to...    0.30     0.60  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213ab1c",
   "metadata": {},
   "source": [
    "- So, the agreement score for the +ve proposition is 0.35. I also try switching the +ve and -ve P for consistency.\n",
    "- Something like a full debate/essay dataset would make a lot more sense here\n",
    "- Full eval sweeps can also be set up to arrive at more robust results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2dac5",
   "metadata": {},
   "source": [
    "## Simple Prompting - Multiple Propositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb197e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROMPT_2 = \"\"\"\n",
    "\n",
    "I need your help scoring a text's agreement to a given belief. Answer with a float in the range [0,1] for each proposition, with 0 being strong disagreement with the proposition/belief and 1 being strong agreement.\n",
    "\n",
    "I have a text, and would like to know to what extent it agrees with my propositions: \n",
    "{p1}: {{\"belief\"}},\n",
    "{p2}: {{\"belief\"}}: ,\n",
    "{p3}: {{\"belief\"}}: \n",
    "Represent the agreement score of each of these propositions with the text by a floating-point probability in [0,1]. \n",
    "Respond in this format, with nothing else: fill in the above proposition-belief blanks - return the entire original proposition as is.\n",
    "\n",
    "The text that you need to check for belief: {text}\n",
    "\n",
    "Remember that you are estimating the probability of the propositions statements being the correct answer, not the opposite.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84f1f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_belief_claude_2(text, p1, p2, p3, model) -> str:\n",
    "    history = [\n",
    "        # {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": USER_PROMPT_2.format(p1=p1, p2=p2, p3=p3, text=text),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        messages=history\n",
    "    )\n",
    "    return (message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "29c77fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opinons = load_from_json(\"opinions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d7d1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[]\n",
    "for rec in opinons:\n",
    "    p1 = rec['p1']\n",
    "    p2 = rec['p2']\n",
    "    p3 = rec['p3']\n",
    "    text = rec['text']\n",
    "\n",
    "    presp = get_belief_claude_2(text, p1, p2, p3, claude)\n",
    "    \n",
    "    l.append((p1, p2, p3, presp[0].text))\n",
    "opinion_df = pd.DataFrame(l, columns=['P1', 'P2', 'P3', 'Belief'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13ce8e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is our capacity for sin that makes us mortal: {\"belief\": 0.2},\n",
      "It was only women who were victims of punishment: {\"belief\": 0.0},\n",
      "Women were unfairly punished only by other men: {\"belief\": 0.1}\n",
      "The actual price of different packaging, colors and scents warrants pink tax: {\"belief\": 0.1},\n",
      "Women just ought to buy products marketed towards men if they want cheaper stuff: {\"belief\": 0.2},\n",
      "Bussinesses ought to continue with pink tax as it is profitable: {\"belief\": 0.0}\n",
      "All Women throughout history have demonstrated empathy for their fellow women's plights. : 0.1\n",
      "\n",
      "People's upbringing contribute to their propensity to undermine others: 0.9\n",
      "\n",
      "Internalized misogyny harms women more then misogyny does: 0.8\n",
      "Men always believe in God for selfless reasons: {\"belief\": 0.2},\n",
      "The debate over the existence of God always unites people, even as it divides: {\"belief\": 0.8},\n",
      "Scientists are of the opinion that the existence of God agrees with probability: {\"belief\": 0.3}\n",
      "Darcy redeems himself despite his hiporcisy and prejudice.: 0.9,\n",
      "Thelower gentry were often blindly societal rules: 0.8,\n",
      "Darcy is a disagreeable character: 0.1\n"
     ]
    }
   ],
   "source": [
    "for b in opinion_df.Belief:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c593b7",
   "metadata": {},
   "source": [
    "Well, that seems to make sense ^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7e606",
   "metadata": {},
   "source": [
    "## Embedding based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88624c3",
   "metadata": {},
   "source": [
    "This particular embedding, at least, does not perform as weel(for obvious reasons though-  the sentence transformers were probably not meant for such comparisons and the set up is just a straightforward cosine similarity metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22d05ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7415a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semsim(real, pred): #list of sentences each ie. all test data\n",
    "  \n",
    "    ##################################################\n",
    "    \n",
    "    mod_name = \"all-mpnet-base-v2\"\n",
    "    # mod_name = \"all-MiniLM-L6-v2\"\n",
    "    # mod_name = 'sentence-transformers/distilroberta-base-paraphrase-v1'\n",
    "    \n",
    "    model = SentenceTransformer(mod_name)\n",
    "    model = model.eval()\n",
    "    # model = model.eval().to(device)\n",
    "    ##################################################\n",
    "    # texts1, texts2 = batch_proc(real, pred)\n",
    "    # all_batch_avg = []\n",
    "    for (text1, text2) in zip(real, pred):\n",
    "        \n",
    "        e1 = model.encode(text1, show_progress_bar = False)\n",
    "        e2 = model.encode(text2, show_progress_bar = False)\n",
    "    \n",
    "        similarities = util.pytorch_cos_sim(e1, e2)\n",
    "        # sims = torch.diagonal(similarities, 0).tolist() #all scores else, have to parse with for loop for each sent\n",
    "\n",
    "        # avg_sim = sum(sims)/len(sims)\n",
    "        # all_batch_avg.append(avg_sim)\n",
    "        # all_batch_avg.append(sims)\n",
    "        \"\"\"#########################################################################\"\"\"\n",
    "    # scores = []\n",
    "    # for i in all_batch_avg:\n",
    "    #     scores += i\n",
    "\n",
    "    \n",
    "    print(real, similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59ff97c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People's behaviour is largely determined by forces not of their own making tensor([[0.4734]])\n",
      "People's behaviour is seldom ever determined by forces not of their own making tensor([[0.4818]])\n",
      "A nation should require all of its students to study the same national curriculum until they enter colloege.  tensor([[1.]])\n",
      "A nation should not require all of its students to study the same national curriculum until they enter colloege.  tensor([[0.2362]])\n"
     ]
    }
   ],
   "source": [
    "for rec in essays:\n",
    "    proposition = rec['proposition']\n",
    "    neg_prop = rec['neg_prop']\n",
    "    text = rec['text']\n",
    "\n",
    "    semsim(proposition, text)\n",
    "    semsim(neg_prop, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f9b4cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is our capacity for sin that makes us mortal tensor([[0.2198]])\n",
      "It was only women who were victims of punishment tensor([[0.3027]])\n",
      "Women were unfairly punished only by other men  tensor([[1.]])\n",
      "\n",
      "\n",
      "\n",
      "The actual price of different packaging, colors and scents warrants pink tax tensor([[0.2417]])\n",
      "Women just ought to buy products marketed towards men if they want cheaper stuff tensor([[0.4084]])\n",
      "Bussinesses ought to continue with pink tax as it is profitable tensor([[0.2377]])\n",
      "\n",
      "\n",
      "\n",
      "All Women throughout history have demonstrated empathy for their fellow women's plights.  tensor([[0.2377]])\n",
      "People's upbringing contribute to their propensity to undermine others tensor([[0.2434]])\n",
      "Internalized misogyny harms women more then misogyny does tensor([[0.3306]])\n",
      "\n",
      "\n",
      "\n",
      "Men always beleive in God for selfless reasons tensor([[0.2566]])\n",
      "The debate over the existence of God always unites people, even as it divides tensor([[0.2434]])\n",
      "Scientists are of the opinon that the exsistence of God agrees with probability tensor([[0.4499]])\n",
      "\n",
      "\n",
      "\n",
      "Darcy redeems himself despite his hiporcisy and prejudice. tensor([[0.2552]])\n",
      "Thelower gentry were often blindly societal rules tensor([[0.3111]])\n",
      "Darcy is a disagreeable character tensor([[0.3585]])\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rec in opinons:\n",
    "    p1 = rec['p1']\n",
    "    p2 = rec['p2']\n",
    "    p3 = rec['p3']\n",
    "    text = rec['text']\n",
    "\n",
    "    semsim(p1, text)\n",
    "    semsim(p2, text)\n",
    "    semsim(p3, text)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b316b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
